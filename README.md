# NewsRagnarok Crawler

RSS feed crawler for news articles with vector database indexing and comprehensive monitoring.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env
# Edit .env with your credentials

# Run crawler
python main.py
```

## ğŸ“ Structure

```
/NewsRagnarok-Crawler
â”œâ”€â”€ main.py (crawler entry point)
â”œâ”€â”€ requirements.txt (crawler dependencies)
â”œâ”€â”€ config/ (sources.yaml)
â”œâ”€â”€ crawler/ (crawler modules)
â”œâ”€â”€ crawlers/ (additional crawlers)
â”œâ”€â”€ clients/ (Qdrant, Redis clients)
â”œâ”€â”€ utils/ (utilities)
â”œâ”€â”€ models/ (data models)
â”œâ”€â”€ monitoring/ (monitoring modules)
â”œâ”€â”€ docs/ (documentation)
â””â”€â”€ .env (environment variables)
```

## ğŸ”§ Features

- âœ… RSS feed parsing and article extraction
- âœ… Vector database indexing (Qdrant)
- âœ… Azure Blob Storage archival
- âœ… Redis caching for performance
- âœ… Configurable data sources
- âœ… Comprehensive monitoring with Azure Application Insights
- âœ… Duplicate detection to prevent redundant processing
- âœ… Secure credential management
- âœ… Health check API endpoints

## ğŸ“Š Data Sources

- BabyPips (RSS)
- FXStreet (RSS)
- ForexLive (RSS)
- Kabutan (HTML)

## ğŸ’¡ Benefits

- âœ… Lightweight (~300MB memory usage)
- âœ… No browser dependencies for core functionality
- âœ… Simple RSS-based discovery
- âœ… Easy to extend with new sources
- âœ… Comprehensive monitoring and alerting
- âœ… Duplicate detection for efficiency
- âœ… Secure by design

## ğŸ”— Dependencies

- **Vector Storage**: Qdrant for semantic search
- **Content Caching**: Redis for performance optimization
- **Archival Storage**: Azure Blob Storage
- **RSS Processing**: Feedparser
- **Monitoring**: Azure Application Insights
- **Content Extraction**: BeautifulSoup, crawl4ai (optional)

## ğŸ“Š Monitoring

The crawler includes comprehensive monitoring capabilities:

- **Local Metrics**: JSON file-based metrics collection
- **Cloud Monitoring**: Azure Application Insights integration
- **Health API**: RESTful health check endpoints
- **Duplicate Detection**: Prevents redundant processing
- **Resource Monitoring**: Memory and CPU tracking
- **Dependency Checks**: Monitoring of external services

For monitoring setup, see the [Application Insights Setup Guide](docs/app_insights_setup.md).

## ğŸ”’ Security Features

- Environment-based credential management
- No hardcoded secrets
- Path validation for file operations
- URL validation and sanitization
- Comprehensive error handling
- Content sanitization before storage
- Memory usage monitoring and management

## ğŸ”„ Process Management

The crawler runs two key processes:

1. **5-Minute Crawl Cycles**: Regular crawling of RSS feeds for new content
2. **Daily Cleanup Process**: Removal of old data to maintain storage efficiency

Both processes are monitored with detailed metrics and health checks.

## ğŸ“ Configuration

Configuration is managed through:

- `.env` file for credentials and API keys
- `config/sources.yaml` for data source configuration

## ğŸ”§ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/newsraag-crawler.git
cd newsraag-crawler

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env
# Edit .env with your credentials

# Test Application Insights setup (optional)
python tests/test_app_insights.py

# Run the crawler
python main.py
```

## ğŸ“ˆ Health Check API

The crawler exposes two API endpoints:

- `/health` - Basic health status and dependency information
- `/metrics` - Detailed metrics about crawler performance

Access these endpoints at `http://localhost:8000/` when the crawler is running.


